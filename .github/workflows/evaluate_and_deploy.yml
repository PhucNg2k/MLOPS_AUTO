name: Evaluate and Deploy Model

on:
  push:
    branches:
      - dev
    paths:
      - 'data/models/final/**'  # Catch any changes in models directory
      - 'src/**'                # Keep watching source code changes

permissions:
  contents: write
  issues: write

jobs:
  evaluate:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
      with:
        fetch-depth: 0
        ref: dev
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ secrets.AWS_DEFAULT_REGION }}
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Create directories
      run: |
        mkdir -p validation_data evaluation_results
        chmod -R 755 validation_data evaluation_results
        
    - name: Find latest model and training data hash
      id: find_model
      run: |
        latest_model=$(ls -t data/models/final/model_*.pth 2>/dev/null | head -n1)
        if [ -z "$latest_model" ]; then
          echo "No model found in data/models/final directory"
          exit 1
        fi
        echo "model_path=$latest_model" >> $GITHUB_OUTPUT
        echo "Found latest model: $latest_model"
        
        # Extract training data hash from DVC metadata file
        dvc_meta="${latest_model}.dvc"
        if [ -f "$dvc_meta" ]; then
          training_hash=$(cat $dvc_meta | grep -oP 'md5: \K[a-f0-9]+')
          echo "training_hash=$training_hash" >> $GITHUB_OUTPUT
          echo "Found training data hash: $training_hash"
        else
          echo "Warning: No DVC metadata found for model, data lineage will not be tracked"
        fi
    
    - name: Download validation dataset
      run: |
        BUCKET_PATH="${{ secrets.VALIDATE_BUCKET }}"
        aws s3 sync s3://$BUCKET_PATH validation_data/
        chmod -R 755 validation_data
        
        if [ ! -e "./validation_data/images" ] || [ ! -e "./validation_data/image_labels.json" ]; then
          echo "Error: Required validation files missing"
          exit 1
        fi
    
    - name: Run evaluation
      id: evaluate
      run: |
        python src/evaluate.py \
          --model_path ${{ steps.find_model.outputs.model_path }} \
          --data_dir validation_data \
          --output_dir evaluation_results \
          --threshold 85.0
          
        echo "metrics=$(cat evaluation_results/eval_metrics.json)" >> $GITHUB_OUTPUT
    
    - name: Check evaluation results
      id: check_eval
      run: |
        metrics='${{ steps.evaluate.outputs.metrics }}'
        current_accuracy=$(echo $metrics | python -c "import sys, json; print(json.load(sys.stdin)['test_accuracy'])")
        threshold=85.0
        
        echo "Current accuracy: $current_accuracy%"
        echo "Required threshold: $threshold%"
        
        if (( $(echo "$current_accuracy >= $threshold" | bc -l) )); then
          echo "merge=true" >> $GITHUB_OUTPUT
          echo "Model meets accuracy threshold!"
        else
          echo "merge=false" >> $GITHUB_OUTPUT
          echo "Model did not meet accuracy threshold"
        fi
    
    - name: Deploy to production if passed
      if: steps.check_eval.outputs.merge == 'true'
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        git config --global user.email "github-actions@github.com"
        git config --global user.name "GitHub Actions"
        
        # Setup production directory
        mkdir -p data/models/production
        cp ${{ steps.find_model.outputs.model_path }} data/models/production/model_production.pth
        
        # 1. Push actual files to S3 via DVC
        dvc init --no-scm
        dvc remote add -f storage ${{ secrets.DVC_REMOTE_URL }}
        dvc remote modify --local storage access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
        dvc remote modify --local storage secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        
        # Track and push model file to S3
        dvc add data/models/production/model_production.pth
        dvc push
        
        # Create and push metadata
        cat > data/models/production/training_metadata.json << EOL
        {
          "model_file": "model_production.pth",
          "training_data_hash": "${{ steps.find_model.outputs.training_hash }}",
          "accuracy": $(echo ${{ steps.evaluate.outputs.metrics }} | python -c 'import sys,json; print(json.load(sys.stdin)["test_accuracy"])'),
          "evaluation_date": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
          "source_model": "$(basename ${{ steps.find_model.outputs.model_path }})"
        }
        EOL
        dvc add data/models/production/training_metadata.json
        dvc push
        
        # 2. Only push hashes to GitHub main
        rm data/models/production/model_production.pth
        rm data/models/production/training_metadata.json
        git add data/models/production/*.dvc evaluation_results/
        
        git commit -m "Deploy model to production [skip ci]

        Evaluation Results:
        - Accuracy: $(echo ${{ steps.evaluate.outputs.metrics }} | python -c 'import sys,json; print(json.load(sys.stdin)["test_accuracy"])')%
        - Status: PASSED
        - Training Data Hash: ${{ steps.find_model.outputs.training_hash }}"
        
        git checkout main
        git pull origin main
        git merge --no-ff dev -m "Merge dev: Deploy model to production"
        git push origin main
    
    - name: Create issue if failed
      if: steps.check_eval.outputs.merge == 'false'
      uses: actions/github-script@v4
      with:
        script: |
          github.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: 'Model Evaluation Failed',
            body: `Model did not meet accuracy threshold (85%)
            
            Evaluation Results:
            ${process.env.METRICS}
            
            Training Data Hash: ${process.env.TRAINING_HASH}
            
            To reproduce training:
            1. Checkout this commit
            2. Use DVC to get data version: ${process.env.TRAINING_HASH}`,
            labels: ['model-evaluation', 'failed']
          })
      env:
        METRICS: ${{ steps.evaluate.outputs.metrics }}
        TRAINING_HASH: ${{ steps.find_model.outputs.training_hash }} 