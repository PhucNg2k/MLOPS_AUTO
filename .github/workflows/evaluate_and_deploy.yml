name: Evaluate and Deploy Model

on:
  push:
    branches:
      - dev
    paths:
      - 'data/models/final/**'  # Catch any changes in models directory
      - 'src/**'                # Keep watching source code changes
  workflow_dispatch:  # Allow manual trigger
    inputs:
      reason:
        description: 'Reason for manual trigger'
        required: false
        default: 'Manual evaluation requested'

permissions:
  contents: write
  issues: write

jobs:
  evaluate:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
      with:
        fetch-depth: 0
        ref: dev
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ secrets.AWS_DEFAULT_REGION }}
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Create directories
      run: |
        mkdir -p validation_data evaluation_results
        chmod -R 755 validation_data evaluation_results
        
    - name: Find latest model and download from S3
      id: find_model
      run: |
        # Find latest DVC file first by modification time
        latest_dvc=$(find data/models/final -name "model_*.pth.dvc" -type f -printf '%T@ %p\n' | sort -nr | head -n1 | cut -d' ' -f2)
        if [ -z "$latest_dvc" ]; then
          echo "No DVC file found in data/models/final directory"
          exit 1
        fi
        
        # Get model filename from DVC file name
        model_filename=$(basename "${latest_dvc%.dvc}")
        echo "Found latest model DVC file: $latest_dvc for model: $model_filename"
        
        # Download model file directly from S3
        aws s3 cp "${{ secrets.DVC_REMOTE_URL }}/$model_filename" "data/models/final/$model_filename"
        
        if [ ! -f "data/models/final/$model_filename" ]; then
          echo "Failed to download model file from S3"
          exit 1
        fi
        
        echo "model_path=data/models/final/$model_filename" >> $GITHUB_OUTPUT
        echo "Found and downloaded latest model: $model_filename"
    
    - name: Download validation dataset
      run: |
        # Remove s3:// prefix if present
        BUCKET_PATH="${{ secrets.VALIDATE_BUCKET }}"
        BUCKET_NAME=${BUCKET_PATH#"s3://"}
        
        # Download validation dataset from bucket root
        aws s3 sync s3://$BUCKET_NAME validation_data/
        chmod -R 755 validation_data
        
        # Verify required files exist
        if [ ! -e "./validation_data/images" ] || [ ! -e "./validation_data/image_labels.json" ] || [ ! -e "./validation_data/validation_set_stats.json" ]; then
          echo "Error: Required validation files missing"
          echo "Contents of validation_data:"
          ls -la ./validation_data/
          exit 1
        fi
        
        echo "Successfully downloaded validation dataset with required files"
    
    - name: Run evaluation
      id: evaluate
      run: |
        python src/evaluate.py \
          --model_path ${{ steps.find_model.outputs.model_path }} \
          --data_dir validation_data \
          --output_dir evaluation_results \
          --threshold 85.0
          
        # Read and format metrics properly for GitHub Actions output
        metrics=$(cat evaluation_results/eval_metrics.json | tr -d '\n\r')
        echo "metrics=${metrics}" >> $GITHUB_OUTPUT
    
    - name: Check evaluation results
      id: check_eval
      run: |
        # Parse metrics using Python to handle JSON properly
        metrics='${{ steps.evaluate.outputs.metrics }}'
        current_accuracy=$(echo "$metrics" | python3 -c "import sys, json; print(json.load(sys.stdin)['test_accuracy'])")
        threshold=85.0
        
        echo "Current accuracy: $current_accuracy%"
        echo "Required threshold: $threshold%"
        
        # Use bc for floating point comparison
        if (( $(echo "$current_accuracy >= $threshold" | bc -l) )); then
          echo "merge=true" >> $GITHUB_OUTPUT
          echo "Model meets accuracy threshold!"
        else
          echo "merge=false" >> $GITHUB_OUTPUT
          echo "Model did not meet accuracy threshold"
        fi
    
    - name: Deploy to production if passed
      if: steps.check_eval.outputs.merge == 'true'
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        git config --global user.email "github-actions@github.com"
        git config --global user.name "GitHub Actions"
        
        # Check if main exists and create if needed
        if git fetch origin main; then
          echo "Main branch exists, checking out..."
          git checkout main
          git pull origin main
        else
          echo "Creating new main branch..."
          git checkout -b main
        fi
        
        # Create temp directories outside git workspace and preserve files
        TEMP_DIR="/tmp/model_backup_$$"
        mkdir -p "$TEMP_DIR/evaluation_results" "$TEMP_DIR/models"
        
        # Copy files with error checking
        if [ -d "evaluation_results" ] && [ "$(ls -A evaluation_results 2>/dev/null)" ]; then
          echo "Backing up evaluation results..."
          cp -r evaluation_results/* "$TEMP_DIR/evaluation_results/"
        else
          echo "No evaluation results found to backup"
          exit 1
        fi
        
        if [ -d "data/models/final" ] && [ "$(ls -A data/models/final/*.dvc 2>/dev/null)" ]; then
          echo "Backing up model DVC files..."
          cp -r data/models/final/*.dvc "$TEMP_DIR/models/"
        else
          echo "No model DVC files found to backup"
          exit 1
        fi
        
        # Reset working directory but don't commit
        git rm -rf . --cached
        git clean -fdx
        
        # Create necessary directories and restore files
        mkdir -p data/models/final evaluation_results
        
        # Restore files with error checking
        echo "Restoring evaluation results..."
        cp -r "$TEMP_DIR/evaluation_results/"* evaluation_results/
        
        echo "Restoring model DVC files..."
        cp -r "$TEMP_DIR/models/"* data/models/final/
        
        # Clean up temp directory
        rm -rf "$TEMP_DIR"
        
        # Stage and commit if there are changes
        git add data/models/final/*.dvc evaluation_results/
        if git diff --staged --quiet; then
          echo "No changes to commit"
          exit 0
        else
          # Use the accuracy value we already calculated
          git commit -m "Update production model - Accuracy: $current_accuracy% - Model: $(basename ${{ steps.find_model.outputs.model_path }})"
          # Force push to main since we want to reset state but keep history
          git push -f origin main
        fi
    
    - name: Create issue if failed
      if: steps.check_eval.outputs.merge == 'false'
      uses: actions/github-script@v4
      with:
        script: |
          github.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: 'Model Evaluation Failed',
            body: `Model did not meet accuracy threshold (85%)
            
            Evaluation Results:
            ${process.env.METRICS}
            
            To reproduce:
            1. Checkout this commit
            2. See .dvc file for model version`,
            labels: ['model-evaluation', 'failed']
          })
      env:
        METRICS: ${{ steps.evaluate.outputs.metrics }} 